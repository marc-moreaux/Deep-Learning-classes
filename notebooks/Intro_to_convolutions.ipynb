{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use of convolutions with tensorflow\n",
    "\n",
    "In this notebook, you'll be using tensorflow to build a Convolutional Neural Network (CNN).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution\n",
    "\n",
    "Both, [this notebook](https://nbviewer.jupyter.org/github/marc-moreaux/Deep-Learning-classes/blob/master/notebooks/Convolution.ipynb) and this [wikipedia page](https://en.wikipedia.org/wiki/Convolution) might help you understand what is a convolution.\n",
    "\n",
    "no, if we consider two functions $f$ and $g$ taking values from $\\mathbb{Z} \\to \\mathbb{R}$ then:  \n",
    "$ (f * g)[n] = \\sum_{m = -\\infty}^{+\\infty} f[m] \\cdot g[n - m] $\n",
    "\n",
    "In our case, we consider the two vectors $x$ and $w$ :  \n",
    "$ x = (x_1, x_2, ..., x_{n-1}, x_n) $  \n",
    "$ w = (w_1, w_2) $\n",
    "\n",
    "And get :   \n",
    "$ x * w = (w_1 x_1 + w_2 x_2, w_1 x_2 + w_2 x_3, ..., w_1 x_{n-1} + w_2 x_n)$\n",
    "\n",
    "\n",
    "#### Deep learning subtility :\n",
    "    \n",
    "In most of deep learning framewoks, you'll get to chose in between three paddings:\n",
    "- **Same**: $(f*g)$ has the same shape as x (we pad the entry with zeros)\n",
    "- **valid**: $(f*g)$ has the shape of x minus the shape of w plus 1 (no padding on x)\n",
    "- **Causal**: $(f*g)(n_t)$ does not depend on any $(n_{t+1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow\n",
    "\n",
    "\"TensorFlow is an open-source software library for dataflow programming across a range of tasks. It is a symbolic math library, and also used for machine learning applications such as neural networks.[3] It is used for both research and production at Google often replacing its closed-source predecessor, DistBelief.\" - Wikipedia\n",
    "\n",
    "We'll be using tensorflow to build the models we want to use. \n",
    "\n",
    "Here below, we build a AND gate with a very simple neural network :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Define our Dataset\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([0,0,0,1]).reshape(-1,1)\n",
    "\n",
    "\n",
    "# Define the tensorflow tensors\n",
    "x = tf.placeholder(tf.float32, [None, 2], name='X')  # inputs\n",
    "y = tf.placeholder(tf.float32, [None, 1], name='Y')  # outputs\n",
    "W = tf.Variable(tf.zeros([2, 1]), name='W')\n",
    "b = tf.Variable(tf.zeros([1,]), name='b')\n",
    "\n",
    "# Define the model\n",
    "pred = tf.nn.sigmoid(tf.matmul(x, W) + b)  # Model\n",
    "\n",
    "# Define the loss\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred) + (1-y) * tf.log(1-pred), reduction_indices=1))\n",
    "\n",
    "# Define the optimizer method you want to use\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# Include some Tensorboard visualization\n",
    "writer_train = tf.summary.FileWriter(\"./my_model/\")\n",
    "writer_train.add_graph(sess.graph)\n",
    "\n",
    "\n",
    "# Start training session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(1000):\n",
    "        _, c, p = sess.run([optimizer, loss, pred], feed_dict={x: X,\n",
    "                                                      y: Y})\n",
    "print p, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the graph you just created, launch tensorbord.  \n",
    "`$tensorboard --logdirs=./` on linux (with corresponding logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Get inspiration from the preceding code to build a XOR gate\n",
    "\n",
    "Design a neural network with 2 layers.\n",
    "- layer1 has 2 neurons (sigmoid or tanh activation)\n",
    "- Layer2 has 1 neuron (it outouts the prediction)\n",
    "\n",
    "And train  it\n",
    "\n",
    "It's **mandatory** that you get a **tensorboard visualization** of your graph, try to make it look good, plz :)\n",
    "\n",
    "Here below I put a graph of the model you want to have (yet your weights won't be the same)\n",
    "![graph](https://i.stack.imgur.com/nRZ6z.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the weights of your model\n",
    "And give an interpretation on what they are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Build a CNN to predict the MNIST digits\n",
    "You can now move to CNNs. You'll have to train a convolutional neural network to predict the digits from MNIST.\n",
    "\n",
    "You might want to reuse some pieces of code from [SNN](https://nbviewer.jupyter.org/github/marc-moreaux/Deep-Learning-classes/blob/master/notebooks/Intro_to_SNN.ipynb)\n",
    "\n",
    "Your model should have 3 layers:\n",
    "- 1st layer : 6 convolutional kernels with shape (3,3)\n",
    "- 2nd layer : 6 convolutional kernels with shape (3,3)\n",
    "- 3rd layer : Softmax layer\n",
    "\n",
    "Train your model.\n",
    "\n",
    "Explain all you do, and why, make it lovely to read, plz o:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the weights of your model\n",
    "And give an interpretation on what they are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chose one (tell me what you chose...)\n",
    "- Show how the gradients (show only one kernel) evolve for good and wrong prediction. (hard)\n",
    "- Initialize the kernels with values that make sense for you and show how they evolve. (easy) \n",
    "- When training is finished, show the 6+6=12 results of some convolved immages. (easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Â Code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
